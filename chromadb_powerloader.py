#!/usr/bin/env python3
"""
ChromaDB PowerLoader v2.0 - Optimizat pentru XOFlowers
Compatibil cu ChromaDB 0.5+ 
"""

import chromadb
import pandas as pd
import os
import time
import logging
from typing import List, Dict, Any, Optional
import json
import uuid

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class XOFlowersPowerDB:
    """
    ChromaDB Power Configuration pentru XOFlowers
    - Optimizat pentru cÄƒutÄƒri multilingvale
    - Indexare avansatÄƒ pentru 709+ produse
    - PerformanÈ›Äƒ maximÄƒ pentru vector search
    """
    
    def __init__(self, persist_directory: str = "./chroma_powerdb"):
        self.persist_directory = persist_directory
        self.collection_name = "xoflowers_power_collection"
        
        # CreeazÄƒ directorul dacÄƒ nu existÄƒ
        os.makedirs(persist_directory, exist_ok=True)
        
        # IniÈ›ializare client ChromaDB
        logger.info(f"ğŸ”§ Initializing ChromaDB client at {persist_directory}")
        self.client = chromadb.PersistentClient(path=persist_directory)
        
        self.collection = None
        
        logger.info("âœ… ChromaDB PowerLoader initialized")
    
    def reset_collection(self) -> bool:
        """ReseteazÄƒ colecÈ›ia pentru o Ã®ncÄƒrcare fresh"""
        try:
            # ÃncearcÄƒ sÄƒ È™teargÄƒ colecÈ›ia existentÄƒ
            try:
                self.client.delete_collection(name=self.collection_name)
                logger.info(f"ğŸ—‘ï¸ Deleted existing collection: {self.collection_name}")
            except:
                logger.info(f"â„¹ï¸ No existing collection to delete")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error resetting collection: {e}")
            return False
    
    def create_power_collection(self) -> bool:
        """CreeazÄƒ colecÈ›ia optimizatÄƒ"""
        try:
            # ReseteazÄƒ colecÈ›ia
            self.reset_collection()
            
            # CreeazÄƒ colecÈ›ia nouÄƒ
            self.collection = self.client.create_collection(
                name=self.collection_name,
                metadata={
                    "description": "XOFlowers Products - Power Search Enabled",
                    "version": "2.0",
                    "total_products": 0,
                    "created_at": time.strftime("%Y-%m-%d %H:%M:%S"),
                    "model": "multilingual-optimized"
                }
            )
            
            logger.info(f"âœ… Created power collection: {self.collection_name}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error creating collection: {e}")
            return False
    
    def load_chunks_data(self, csv_path: str = "chunks_data.csv") -> pd.DataFrame:
        """ÃncarcÄƒ datele din chunks_data.csv"""
        try:
            if not os.path.exists(csv_path):
                logger.error(f"âŒ File not found: {csv_path}")
                return pd.DataFrame()
            
            df = pd.read_csv(csv_path, encoding='utf-8')
            logger.info(f"ğŸ“Š Loaded {len(df)} total records from {csv_path}")
            
            # Filtrare doar produse
            product_df = df[df['chunk_type'] == 'product'].copy()
            logger.info(f"ğŸŒ¸ Found {len(product_df)} products")
            
            # Cleanup date
            product_df = product_df.dropna(subset=['primary_text'])
            product_df['price'] = pd.to_numeric(product_df['price'], errors='coerce').fillna(0)
            
            # AdaugÄƒ ID-uri unice
            product_df['unique_id'] = [str(uuid.uuid4()) for _ in range(len(product_df))]
            
            logger.info(f"âœ… Prepared {len(product_df)} clean products for loading")
            return product_df
            
        except Exception as e:
            logger.error(f"âŒ Error loading data: {e}")
            return pd.DataFrame()
    
    def enhance_product_text(self, row: pd.Series) -> str:
        """ÃmbunÄƒtÄƒÈ›eÈ™te textul pentru cÄƒutare optimÄƒ"""
        # Text principal
        text = str(row['primary_text'])
        
        # AdaugÄƒ informaÈ›ii structurate
        if pd.notna(row['category']):
            text += f" | Categorie: {row['category']}"
        
        if pd.notna(row['flower_type']):
            text += f" | Flori: {row['flower_type']}"
        
        if pd.notna(row['price']) and row['price'] > 0:
            text += f" | PreÈ›: {int(row['price'])} MDL"
        
        # Termeni de cÄƒutare romÃ¢neÈ™ti
        flower_type = str(row['flower_type']).lower()
        
        # MapÄƒri pentru cÄƒutare mai bunÄƒ
        search_terms = []
        if 'rose' in flower_type or 'trandafir' in flower_type:
            search_terms.append("trandafiri roses")
        if 'peony' in flower_type or 'peon' in flower_type:
            search_terms.append("bujori peonies")
        if 'hydrangea' in flower_type:
            search_terms.append("hortensie hydrangea")
        if 'diffuser' in flower_type or 'difuzor' in flower_type:
            search_terms.append("difuzor aromÄƒ")
        
        if search_terms:
            text += f" | CÄƒutare: {' '.join(search_terms)}"
        
        return text
    
    def create_metadata(self, row: pd.Series) -> Dict[str, Any]:
        """CreeazÄƒ metadata pentru fiecare produs"""
        price = float(row['price']) if pd.notna(row['price']) else 0.0
        
        # DeterminÄƒ categoria de preÈ›
        if price <= 0:
            price_range = "unknown"
        elif price < 600:
            price_range = "budget"
        elif price < 1200:
            price_range = "mid"
        elif price < 2500:
            price_range = "premium"
        else:
            price_range = "luxury"
        
        metadata = {
            "chunk_id": str(row['chunk_id']),
            "category": str(row['category']) if pd.notna(row['category']) else "",
            "flower_type": str(row['flower_type']) if pd.notna(row['flower_type']) else "",
            "price": price,
            "price_range": price_range,
            "url": str(row['url']) if pd.notna(row['url']) else "",
            
            # Flags pentru cÄƒutare rapidÄƒ
            "has_roses": "rose" in str(row['flower_type']).lower() or "trandafir" in str(row['flower_type']).lower(),
            "has_peonies": "peony" in str(row['flower_type']).lower() or "peon" in str(row['flower_type']).lower(),
            "is_diffuser": "diffuser" in str(row['flower_type']).lower() or "difuzor" in str(row['flower_type']).lower(),
            "is_bouquet": "bouquet" in str(row['primary_text']).lower() or "buchet" in str(row['primary_text']).lower(),
            "is_basket": "basket" in str(row['primary_text']).lower() or "coÈ™" in str(row['primary_text']).lower(),
        }
        
        return metadata
    
    def load_products_batch(self, df: pd.DataFrame, batch_size: int = 20) -> bool:
        """ÃncarcÄƒ produsele Ã®n batch-uri"""
        try:
            total_products = len(df)
            logger.info(f"ğŸš€ Starting power loading of {total_products} products...")
            
            successful_loads = 0
            
            for i in range(0, total_products, batch_size):
                batch = df.iloc[i:i + batch_size]
                
                # PregÄƒtire batch
                documents = []
                metadatas = []
                ids = []
                
                for _, row in batch.iterrows():
                    # Text Ã®mbunÄƒtÄƒÈ›it
                    enhanced_text = self.enhance_product_text(row)
                    documents.append(enhanced_text)
                    
                    # Metadata
                    metadata = self.create_metadata(row)
                    metadatas.append(metadata)
                    
                    # ID unic
                    ids.append(str(row['unique_id']))
                
                try:
                    # AdaugÄƒ Ã®n ChromaDB
                    self.collection.add(
                        documents=documents,
                        metadatas=metadatas,
                        ids=ids
                    )
                    
                    successful_loads += len(batch)
                    
                    # Progress
                    progress = min(i + batch_size, total_products)
                    percentage = (progress / total_products) * 100
                    logger.info(f"ğŸ“¦ Batch {progress}/{total_products} loaded ({percentage:.1f}%)")
                    
                except Exception as batch_error:
                    logger.error(f"âŒ Error loading batch {i}: {batch_error}")
                    continue
                
                # PauzÄƒ micÄƒ
                time.sleep(0.05)
            
            logger.info(f"âœ… Successfully loaded {successful_loads}/{total_products} products!")
            
            # ActualizeazÄƒ metadata colecÈ›iei
            if successful_loads > 0:
                self.collection.modify(metadata={"total_products": successful_loads})
            
            return successful_loads > 0
            
        except Exception as e:
            logger.error(f"âŒ Error in batch loading: {e}")
            return False
    
    def verify_database(self) -> Dict[str, Any]:
        """VerificÄƒ starea bazei de date"""
        try:
            count = self.collection.count()
            
            # Test de cÄƒutare
            test_results = self.collection.query(
                query_texts=["trandafiri roÈ™ii"],
                n_results=3
            )
            
            # Statistici
            stats = {
                "total_products": count,
                "collection_name": self.collection_name,
                "database_path": self.persist_directory,
                "test_results_count": len(test_results['documents'][0]) if test_results['documents'] else 0,
                "sample_product": test_results['documents'][0][0][:150] + "..." if test_results['documents'] and test_results['documents'][0] else "No results"
            }
            
            logger.info(f"ğŸ“Š Database verification complete: {count} products")
            return stats
            
        except Exception as e:
            logger.error(f"âŒ Error verifying database: {e}")
            return {}
    
    def create_search_interface(self):
        """CreeazÄƒ interfaÈ›a de cÄƒutare optimizatÄƒ"""
        def power_search(
            query: str,
            n_results: int = 5,
            filters: Optional[Dict] = None
        ) -> Dict[str, Any]:
            """
            CÄƒutare vectorialÄƒ optimizatÄƒ
            
            Args:
                query: Textul de cÄƒutare
                n_results: NumÄƒrul de rezultate
                filters: Filtre (price_range, category, etc.)
            
            Returns:
                Rezultate formatate
            """
            try:
                # Construire filtru where
                where_clause = {}
                if filters:
                    if filters.get('price_range'):
                        where_clause['price_range'] = filters['price_range']
                    if filters.get('category'):
                        where_clause['category'] = {"$contains": filters['category']}
                    if filters.get('has_roses'):
                        where_clause['has_roses'] = True
                    if filters.get('has_peonies'):
                        where_clause['has_peonies'] = True
                
                # ExecutÄƒ cÄƒutarea
                results = self.collection.query(
                    query_texts=[query],
                    n_results=n_results,
                    where=where_clause if where_clause else None
                )
                
                # Formatare rezultate
                formatted_results = []
                if results['documents'] and results['documents'][0]:
                    for i, doc in enumerate(results['documents'][0]):
                        result = {
                            "text": doc,
                            "metadata": results['metadatas'][0][i] if results['metadatas'] else {},
                            "distance": results['distances'][0][i] if results['distances'] else 0,
                            "id": results['ids'][0][i] if results['ids'] else ""
                        }
                        formatted_results.append(result)
                
                return {
                    "query": query,
                    "filters": filters,
                    "results": formatted_results,
                    "count": len(formatted_results)
                }
                
            except Exception as e:
                logger.error(f"âŒ Search error: {e}")
                return {"query": query, "results": [], "count": 0, "error": str(e)}
        
        return power_search
    
    def save_config(self):
        """SalveazÄƒ configuraÈ›ia"""
        config = {
            "persist_directory": self.persist_directory,
            "collection_name": self.collection_name,
            "total_products": self.collection.count() if self.collection else 0,
            "created_at": time.strftime("%Y-%m-%d %H:%M:%S"),
            "version": "2.0"
        }
        
        config_path = os.path.join(self.persist_directory, "xoflowers_config.json")
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ’¾ Configuration saved to {config_path}")
    
    def load_chunks_data(self, csv_path: str = "chunks_data.csv") -> pd.DataFrame:
        """ÃncarcÄƒ È™i proceseazÄƒ datele din chunks_data.csv"""
        try:
            df = pd.read_csv(csv_path, encoding='utf-8')
            logger.info(f"ğŸ“Š Loaded {len(df)} records from {csv_path}")
            
            # Filtrare doar produse (nu colecÈ›ii)
            product_df = df[df['chunk_type'] == 'product'].copy()
            logger.info(f"ğŸŒ¸ Found {len(product_df)} products")
            
            # Cleanup È™i validare date
            product_df = product_df.dropna(subset=['primary_text'])
            product_df['price'] = pd.to_numeric(product_df['price'], errors='coerce').fillna(0)
            
            # AdaugÄƒ ID-uri unice pentru fiecare produs
            product_df['unique_id'] = [str(uuid.uuid4()) for _ in range(len(product_df))]
            
            return product_df
            
        except Exception as e:
            logger.error(f"âŒ Error loading data: {e}")
            return pd.DataFrame()
    
    def enhance_product_text(self, row: pd.Series) -> str:
        """ÃmbunÄƒtÄƒÈ›eÈ™te textul produsului pentru indexare optimÄƒ"""
        # Textul principal
        enhanced_text = row['primary_text']
        
        # AdaugÄƒ informaÈ›ii structurate
        if pd.notna(row['category']):
            enhanced_text += f" | Categorie: {row['category']}"
        
        if pd.notna(row['flower_type']):
            enhanced_text += f" | Tip flori: {row['flower_type']}"
        
        if pd.notna(row['price']) and row['price'] > 0:
            enhanced_text += f" | PreÈ›: {row['price']} MDL"
        
        # AdaugÄƒ termeni de cÄƒutare Ã®n romÃ¢nÄƒ È™i englezÄƒ
        flower_types = str(row['flower_type']).lower()
        if 'trandafir' in flower_types or 'rose' in flower_types:
            enhanced_text += " | trandafiri roses"
        if 'peon' in flower_types:
            enhanced_text += " | bujori peonies"
        if 'hydrangea' in flower_types:
            enhanced_text += " | hortensie hydrangea"
        
        return enhanced_text
    
    def create_metadata(self, row: pd.Series) -> Dict[str, Any]:
        """CreeazÄƒ metadata optimizatÄƒ pentru fiecare produs"""
        metadata = {
            "chunk_id": str(row['chunk_id']),
            "unique_id": str(row['unique_id']),
            "category": str(row['category']) if pd.notna(row['category']) else "",
            "flower_type": str(row['flower_type']) if pd.notna(row['flower_type']) else "",
            "price": float(row['price']) if pd.notna(row['price']) else 0.0,
            "url": str(row['url']) if pd.notna(row['url']) else "",
            "collection_id": str(row['collection_id']) if pd.notna(row['collection_id']) else "",
            
            # Metadate avansate pentru cÄƒutare
            "price_range": self._get_price_range(row['price']),
            "has_roses": "trandafir" in str(row['flower_type']).lower() or "rose" in str(row['flower_type']).lower(),
            "has_peonies": "peon" in str(row['flower_type']).lower(),
            "is_bouquet": "buchet" in str(row['primary_text']).lower() or "bouquet" in str(row['primary_text']).lower(),
            "is_box": "cutie" in str(row['primary_text']).lower() or "box" in str(row['primary_text']).lower(),
            "is_basket": "coÈ™" in str(row['primary_text']).lower() or "basket" in str(row['primary_text']).lower(),
        }
        
        return metadata
    
    def _get_price_range(self, price: float) -> str:
        """DeterminÄƒ categoria de preÈ›"""
        if price <= 0:
            return "unknown"
        elif price < 500:
            return "budget"
        elif price < 1000:
            return "mid"
        elif price < 2000:
            return "premium"
        else:
            return "luxury"
    
    def load_products_in_batches(self, df: pd.DataFrame, batch_size: int = 50) -> bool:
        """ÃncarcÄƒ produsele Ã®n batch-uri pentru performanÈ›Äƒ optimÄƒ"""
        try:
            total_rows = len(df)
            logger.info(f"ğŸš€ Starting batch loading of {total_rows} products...")
            
            for i in range(0, total_rows, batch_size):
                batch = df.iloc[i:i + batch_size]
                
                # PregÄƒtire date pentru batch
                documents = []
                metadatas = []
                ids = []
                
                for _, row in batch.iterrows():
                    # Text Ã®mbunÄƒtÄƒÈ›it pentru embedding
                    enhanced_text = self.enhance_product_text(row)
                    documents.append(enhanced_text)
                    
                    # Metadata optimizatÄƒ
                    metadata = self.create_metadata(row)
                    metadatas.append(metadata)
                    
                    # ID unic
                    ids.append(str(row['unique_id']))
                
                # AdaugÄƒ batch-ul Ã®n ChromaDB
                self.collection.add(
                    documents=documents,
                    metadatas=metadatas,
                    ids=ids
                )
                
                # Progress logging
                progress = min(i + batch_size, total_rows)
                logger.info(f"ğŸ“¦ Loaded batch {progress}/{total_rows} ({progress/total_rows*100:.1f}%)")
                
                # PauzÄƒ micÄƒ pentru a nu suprasolicita memoria
                time.sleep(0.1)
            
            logger.info(f"âœ… Successfully loaded all {total_rows} products to ChromaDB!")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error during batch loading: {e}")
            return False
    
    def verify_loading(self) -> Dict[str, Any]:
        """VerificÄƒ cÄƒ datele au fost Ã®ncÄƒrcate corect"""
        try:
            count = self.collection.count()
            
            # Test query
            test_results = self.collection.query(
                query_texts=["trandafiri roÈ™ii"],
                n_results=3
            )
            
            # Statistici despre colecÈ›ie
            stats = {
                "total_products": count,
                "collection_name": self.collection_name,
                "embedding_model": "paraphrase-multilingual-mpnet-base-v2",
                "test_query_results": len(test_results['documents'][0]) if test_results['documents'] else 0,
                "sample_result": test_results['documents'][0][0] if test_results['documents'] and test_results['documents'][0] else "No results"
            }
            
            logger.info(f"ğŸ“Š Collection Stats: {stats}")
            return stats
            
        except Exception as e:
            logger.error(f"âŒ Error verifying loading: {e}")
            return {}
    
    def create_advanced_search_method(self):
        """CreeazÄƒ metodÄƒ de cÄƒutare avansatÄƒ"""
        def advanced_search(
            query: str,
            n_results: int = 5,
            price_range: Optional[str] = None,
            category: Optional[str] = None,
            flower_type: Optional[str] = None
        ) -> Dict[str, Any]:
            """
            CÄƒutare avansatÄƒ Ã®n ChromaDB
            
            Args:
                query: Textul de cÄƒutare
                n_results: NumÄƒrul de rezultate
                price_range: Filtru preÈ› (budget, mid, premium, luxury)
                category: Filtru categorie
                flower_type: Filtru tip flori
            """
            # Construire filtru where
            where_filter = {}
            
            if price_range:
                where_filter["price_range"] = price_range
            
            if category:
                where_filter["category"] = {"$contains": category}
            
            if flower_type:
                where_filter["flower_type"] = {"$contains": flower_type}
            
            # ExecutÄƒ cÄƒutarea
            results = self.collection.query(
                query_texts=[query],
                n_results=n_results,
                where=where_filter if where_filter else None
            )
            
            return {
                "query": query,
                "filters": where_filter,
                "results": results,
                "count": len(results['documents'][0]) if results['documents'] else 0
            }
        
        return advanced_search
    
    def save_configuration(self):
        """SalveazÄƒ configuraÈ›ia pentru utilizare ulterioarÄƒ"""
        config = {
            "persist_directory": self.persist_directory,
            "collection_name": self.collection_name,
            "embedding_model": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
            "hnsw_params": self.hnsw_params,
            "created_at": time.strftime("%Y-%m-%d %H:%M:%S"),
            "total_products": self.collection.count() if self.collection else 0
        }
        
        config_path = os.path.join(self.persist_directory, "config.json")
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ’¾ Configuration saved to {config_path}")

def main():
    """FuncÈ›ia principalÄƒ"""
    print("ğŸŒ¸ XOFlowers ChromaDB PowerLoader v2.0")
    print("=" * 50)
    
    # VerificÄƒ fiÈ™ierul chunks_data.csv
    csv_file = "chunks_data.csv"
    if not os.path.exists(csv_file):
        print(f"âŒ File not found: {csv_file}")
        print("Please ensure chunks_data.csv is in the current directory")
        return
    
    # IniÈ›ializare PowerDB
    print("ğŸ”§ Initializing XOFlowers PowerDB...")
    power_db = XOFlowersPowerDB()
    
    # CreeazÄƒ colecÈ›ia
    if not power_db.create_power_collection():
        print("âŒ Failed to create collection!")
        return
    
    # ÃncarcÄƒ datele
    print("ğŸ“Š Loading product data...")
    df = power_db.load_chunks_data(csv_file)
    
    if df.empty:
        print("âŒ No products found to load!")
        return
    
    # Proces de Ã®ncÄƒrcare power
    print("ğŸš€ Starting POWER LOADING...")
    start_time = time.time()
    
    success = power_db.load_products_batch(df, batch_size=15)
    
    if success:
        end_time = time.time()
        
        # Verificare finalÄƒ
        print("ğŸ” Verifying database...")
        stats = power_db.verify_database()
        
        # SalveazÄƒ configuraÈ›ia
        power_db.save_config()
        
        # CreeazÄƒ interfaÈ›a de cÄƒutare
        search_func = power_db.create_search_interface()
        
        # AfiÈ™eazÄƒ rezultatele
        print("\n" + "=" * 50)
        print("âœ… POWER LOADING SUCCESSFUL!")
        print(f"â±ï¸  Time: {end_time - start_time:.2f} seconds")
        print(f"ğŸ“Š Products loaded: {stats.get('total_products', 0)}")
        print(f"ğŸ“ Database: {stats.get('database_path', 'Unknown')}")
        print("=" * 50)
        
        # Test rapid
        print("\nğŸ§ª Testing search functionality...")
        test_result = search_func("trandafiri roÈ™ii pentru iubire")
        if test_result['count'] > 0:
            print(f"âœ… Search test successful: {test_result['count']} results")
            print(f"ğŸ“ Top result: {test_result['results'][0]['text'][:100]}...")
        else:
            print("âš ï¸ Search test returned no results")
        
        print("\nğŸ‰ XOFlowers PowerDB is ready for production!")
        print("ğŸ” Vector search enabled with multilingual support")
        
    else:
        print("âŒ Power loading failed!")

if __name__ == "__main__":
    main()
